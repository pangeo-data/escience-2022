{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee67085-c7cb-42e0-893f-9ca7a176a16d",
   "metadata": {},
   "source": [
    "# Data access and discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b9ab8-508f-47f4-85dd-03cb034a8e19",
   "metadata": {},
   "source": [
    "## Authors & Contributors\n",
    "\n",
    "### Authors\n",
    "\n",
    "- Pier Lorenzo Marasco, Ispra (Italy), [@pl-marasco](https://github.com/pl-marasco)\n",
    "- Alejandro Coca-Castro, The Alan Turing Institute (United Kingdom), [@acocac](https://github.com/acocac)\n",
    "\n",
    "### Contributors\n",
    "- Tina Odaka, Ifremer (France), [@tinaok](https://github.com/tinaok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c0486-d262-42b7-b711-45fddaa0bfbc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <i class=\"fa-question-circle fa\" style=\"font-size: 22px;color:#666;\"></i> <b>Overview</b>\n",
    "    <br>\n",
    "    <br>\n",
    "    <b>Questions</b>\n",
    "    <ul>\n",
    "        <li>How to access online (remote) datasets?</li>\n",
    "        <li>How to prepare and discover online geoscience datasets?</li>\n",
    "        <li>What is Analysis Ready, Cloud Optimized data (ARCO)?</li>\n",
    "        <li>What is pangeo-forge?</li>\n",
    "        <li>What is stac?</li>\n",
    "    </ul>\n",
    "    <b>Objectives</b>\n",
    "    <ul>\n",
    "        <li>Learn to access datasets from online object storage</li>\n",
    "        <li>Learn about preparing and discovery online datasets</li>\n",
    "        <li>Learn about Analysis Cloud Optimized (ARCO) data</li>\n",
    "        <li>Learnn about the Pangeo Forge initiative</li>\n",
    "        <li>Learn about stac</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be651606-d4ae-4833-8825-4dc66f2503e1",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "We will be using Long Term Statistics (1999-2019) product provided by the [Copernicus Global Land Service over Lombardia](https://land.copernicus.eu/global/index.html) and access them through [S3-compatible storage](https://en.wikipedia.org/wiki/Amazon_S3). Also we will explore [Sentinel-2 Cloud-Optimised Dataset](https://registry.opendata.aws/sentinel-2-l2a-cogs/) online through [STAC](https://stacspec.org/en)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c3071-fbb6-4419-abb5-3f8783284438",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This episode uses the following Python packages:\n",
    "\n",
    "- xarray\n",
    "- s3fs\n",
    "- datetime\n",
    "- pystac_client\n",
    "\n",
    "Please install these packages if not already available in your Python environment. Below, we only install packages that are not available in the EGI-ACE EOSC deployment of Pangeo for the FOSS4G course.\n",
    "\n",
    "### Packages\n",
    "\n",
    "In this episode, Python packages are imported when we start to use them. However, for best software practices, we recommend you to install and import all the necessary libraries at the top of your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d976a91-0952-4247-9a1e-b52b850fdb7b",
   "metadata": {},
   "source": [
    "## Introduction to the Long Term statistics\n",
    "CGLS LTS are computed over a time span of 20 years aggregated over separate 10-day periods (month/01,month/11, month/21). For each date the long term minimum, maximum, mean, median and standard deviation are computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591f316-6817-4a2e-8f9a-7177c4824587",
   "metadata": {},
   "source": [
    "### S3-compatible Object Storage to access online data\n",
    "\n",
    "Up to now we downloaded data locally and then opened the downloaded file with Xarray `open_dataset`. Each attendee downloaded a copy locally. When willing to manipulate large amount of data, this approach is not optimal (since it requires a lot of unecessary local downloads). Sharing data online as Object Storage allows for data sharing and access to much larger amounts of data.\n",
    "\n",
    "One of the most popular ways to access online remote data is through Amazon Simple Storage Service (S3) and you do not necessarily need to use Amazon services to benefit from S3 Object storage. Many other providers offer S3-compatible object storage that can be accessed in a very similar way.\n",
    "\n",
    "Below we will be accessing online the NDVI Long Term Statistics from Copernicus Land Service that we have publicly stored in OpenStack Object storage (Swift)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4fb7cf-cf82-47e4-8366-4f2dce155fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82f7f9-387f-4f25-b948-c6b4dcaed10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(anon=True,\n",
    "      client_kwargs={\n",
    "         'endpoint_url': 'https://object-store.cloud.muni.cz'\n",
    "      })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0405e6db-753f-4b8f-8135-237ff3f63fc2",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "The parameter `anon` is for `anonymous` and is set to `True` because the data we have stored at `https://object-store.cloud.muni.cz` is public\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea82d0e-ef18-456e-a65e-00dcb9f50a2e",
   "metadata": {},
   "source": [
    "#### List files and folders in existing buckets\n",
    "\n",
    "Instead of organizing files in various folders, object storage systems store files in a flat organization of containers (called \"buckets\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead3b51-aae8-4a8d-9188-df496d1f891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ls('foss4g-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efa44f-1dc5-4289-a78a-c5faae255186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs.ls('foss4g-data/CGLS_LTS_1999_2019_Lombardia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6851335f-8207-4860-870d-8cd31963d70b",
   "metadata": {},
   "source": [
    "#### Access remote files from S3-compatible Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe09d2-9fb2-456f-aac3-d6f38b1cf128",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3path = 's3://foss4g-data/CGLS_LTS_1999_2019_Lombardia/AOI_c_gls_NDVI-LTS_1999-2019-0101_GLOBE_VGT-PROBAV_V3.0.1.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029019e3-6e05-42f7-95d2-1218a45c8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTS = xr.open_dataset(fs.open(s3path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62a7fe-bb13-421f-8003-23a7749fb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1214bb3-e404-4b73-be98-5c9d5072280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTS.sel(lat=45.88, lon=8.63, method='nearest')['min'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b20d20e-c88a-4825-bd70-a8e7d1eb72ef",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "The same dataset can be available from different locations e.g. [CGLS distributor VITO](https://vito.be/en), Zenodo, S3-compatible OpenStack Object storage (Swift), etc.\n",
    "How do you know if it corresponds to the very same dataset? You cannot know except if the datasets have a persistent identifier such as a Digital Object Identifier.\n",
    "It is therefore recommended *1)* to be extra careful about where you get your datasets, and *2)* to double check that the content is exactly what you expect (for instance, you can perform basic quality checks).                                                            \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d6ed7-e43c-4fec-8e34-caf8641948d0",
   "metadata": {},
   "source": [
    "#### Access multiple remote files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366d570-3f48-4e11-a647-5d7caf668276",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3path = 's3://foss4g-data/CGLS_LTS_1999_2019_Lombardia/AOI_c_gls_*.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085418aa-87ef-42c0-aacb-bbcd89543940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote_files = fs.glob(s3path)\n",
    "remote_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8235a22-dfb4-442e-9c78-e450ccd32cce",
   "metadata": {},
   "source": [
    "We need to add a time dimension to concatenate data. For this, we define a function that will be called for each remote file (via the `preprocess` parameter of Xarray `open_mfdataset`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc368c-3aad-4bf8-b249-40768fc6c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128871ee-64ab-421a-bbcd-f9913ae54fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    t = datetime.strptime(ds.attrs['identifier'].split(':')[-1].split('_')[1].replace('1999-', ''), \"%Y-%m%d\")\n",
    "    return(ds.assign_coords(time=t).expand_dims('time'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb2bfc-a068-435a-80b7-bc50a7a8088a",
   "metadata": {},
   "source": [
    "Xarray `open_mfdataset` allows to open multiple files at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b6dd4-05c8-4c0e-8ca8-712665b0af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through remote_files to create a fileset\n",
    "fileset = [fs.open(file) for file in remote_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0e55ec-488a-486c-8d15-83e040ad656b",
   "metadata": {},
   "source": [
    "When opening remote files, you can also select the variables you wish to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485973e-0972-4eba-85c0-50a68689c3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LTS = xr.open_mfdataset(fileset, combine='nested', concat_dim=['time'],  preprocess=preprocess,\n",
    "                        decode_coords=\"all\")\n",
    "LTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e4bbb-2965-462c-bfc7-d7f61531071f",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "If you use one of xarray’s open methods such as xarray.open_dataset to load netCDF files with the default engine, it is recommended to use decode_coords=”all”. This will load the grid mapping variable into coordinates for compatibility with rioxarray. See [rioxarray documentation](https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html#xarray).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1019d9-de17-40ab-850a-0f25ad048e18",
   "metadata": {},
   "source": [
    "## Preparing and discover online datasets\n",
    "\n",
    "With the plethora of cloud storage, there are many available online datasets. To ease the preparation and discovery of such datasets, we describe emerging community-driven initiatives promoting standards suited to both geospatial and geoscience communities. Most of the material below is adapted from a previous Pangeo 101 training {cite:ps}`galaxy2022-pangeo`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7daeb-be5e-4fc8-bee5-bd82a50fa57c",
   "metadata": {},
   "source": [
    "### Analysis Ready, cloud optimized data (ARCO)\n",
    "When analyzing data at scale, the data format used is key. For years, the main data format was netCDF e.g. Network Common Data Form but with the use of cloud computing and interest in Open Science, different formats are often more suitable.\n",
    "\n",
    "Formats for analyzing data from the cloud are refered to as \"Analysis Ready, Cloud Optimized\" data formats or in short ARCO. Find further info about ARCO datasets in {cite:ps}`Abernathey2022-arco`.\n",
    "\n",
    "What is \"Analysis Ready\"?\n",
    "* Think in terms of \"Datasets\" not \"data files\"\n",
    "* No need for tedious homogenizing / cleaning setup guides\n",
    "* Curated and cataloged\n",
    "\n",
    "What is \"Cloud Optimized\"?\n",
    "* Compatible with object storage e.g. access via HTTP\n",
    "* Supports lazy access and intelligent subsetting\n",
    "* Integrates with high-level analysis libraries and distributed frameworks\n",
    "\n",
    "Instead of having a big dataset, ARCO datasets are chunked appropriately for analysis and have rich metadata (See Figure 1).\n",
    "\n",
    "<img src=\"https://github.com/galaxyproject/training-material/blob/696dfecd4c88e59b487a7a3557cfedca6ec5754b/topics/climate/images/arco_data.png?raw=true\" align=\"Left\" /></a>\n",
    "\n",
    "*Fig 1. Example of an ARCO dataset. Source: {cite:ps}`galaxy2022-pangeo`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c8411a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The Pangeo forge initiative\n",
    "\n",
    "[Pangeo Forge](https://pangeo-forge.org/) is an open source platform for data **Extraction**, **Transformation**, and **Loading** (ETL). The goal of *Pangeo Forge* is to make it easy to extract data from traditional repositories and deposit this data in cloud object storage in an analysis-ready, cloud optimized (ARCO) format {cite:ps}`galaxy2022-pangeo`.\n",
    "\n",
    "Pangeo Forge is inspired directly by Conda Forge, a community-led collection of recipes for building conda packages.\n",
    "\n",
    "It is under active development and the Pangeo community hopes it will play a role in democratizing the publication of datasets in ARCO format.\n",
    "\n",
    "#### How does Pangeo Forge work?\n",
    "\n",
    "Pangeo Forge defines the concept of a recipe, which specifies the logic for transforming a specific data archive into an ARCO data store.\n",
    "All contributions to Pangeo Forge must include an executable Python module, named recipe.py or similar, in which the data transformation logic is embedded (Figure 2).\n",
    "The recipe contributor is expected to use one of a predefined set of template algorithms defined by Pangeo Forge.\n",
    "Each of these templated algorithms is designed to transform data of a particular source type into a corresponding ARCO format, and requires only that the contributor populate the template with information unique to their specific data transformation, including the location of the source files and the way in which they should be aligned in the resulting ARCO data store {cite:ps}`Abernathey2022-arco`.\n",
    "\n",
    "The diagram below looks complicated but like for conda forge most of the process is automated.\n",
    "\n",
    "<img src=\"https://www.frontiersin.org/files/Articles/782909/fclim-03-782909-HTML/image_m/fclim-03-782909-g002.jpg\" align=\"Left\" /></a>\n",
    "\n",
    "*Fig 2. A recipe in relation to Pangeo Forge architecture. Source: {cite:ps}`Abernathey2022-arco`.*\n",
    "\n",
    "The next step after preparing the dataset is then to tell the community where and how to access to your transformed dataset.\n",
    "\n",
    "This is done by creating a catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469aa6f",
   "metadata": {},
   "source": [
    "### Spatio Temporal Asset Catalogs (STAC)\n",
    "\n",
    "The [STAC](https://stacspec.org/en/) specification is a common language to describe geospatial information, so it can more easily be worked with, indexed, and discovered.\n",
    "\n",
    "#### Why STAC?\n",
    "* Each provider has its own catalog and interface (APIs).\n",
    "* Every time you want to access a new catalog, you need to change your program.\n",
    "* We have lots of data providers and each with a bespoke interface.\n",
    "* It is becoming quickly difficult for programmers who need to design a new data connector each time.\n",
    "\n",
    "#### Features\n",
    "- STAC catalogs are extremely simple.\n",
    "- They are composed of three layers:\n",
    "    - **Catalogs**\n",
    "        - **Collections**\n",
    "            - **Items**\n",
    "- STAC is very popular for Earth Observation satellite imagery.\n",
    "- For instance it can be used to access Sentinel-2 in AWS (see Figure 3).\n",
    "\n",
    "<img src=\"https://github.com/galaxyproject/training-material/blob/696dfecd4c88e59b487a7a3557cfedca6ec5754b/topics/climate/images/sentinel2_AWS.png?raw=true\" align=\"Left\" /></a>\n",
    "\n",
    "*Fig 1. Example of STAC collection of Sentinel-2 images hosted in AWS. \n",
    "Source: {cite:ps}`galaxy2022-pangeo`.*\n",
    "\n",
    "\n",
    "#### STAC and Pangeo Forge\n",
    "- Pangeo-forge supports the creation of analysis-ready cloud optimized (ARCO) data in cloud object storage from \"classical\" data repositories'\n",
    "- STAC is used to create catalogs and goes beyond the Pangeo ecosystem.\n",
    "- Work is ongoing to figure out the best way to expose Pangeo-Forge-generated data assets via STAC catalogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17df17e-70c7-4120-823d-2df7c535f874",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <i class=\"fa-check-circle fa\" style=\"font-size: 22px;color:#666;\"></i> <b>Key Points</b>\n",
    "    <br>\n",
    "    <ul>\n",
    "        <li>Access to remote dataset</li>\n",
    "        <li>ARCO datasets</li>\n",
    "        <li>Pangeo Forge</li>\n",
    "        <li>STAC</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77853a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "```{bibliography}\n",
    ":style: alpha\n",
    ":filter: topic % \"data-access\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab180d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
